{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:32:10.838555Z",
     "start_time": "2025-05-20T00:32:06.916174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "import os"
   ],
   "id": "3f32a86cfae6018c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 08:32:08.111521: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-20 08:32:08.156801: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747701128.183054  554071 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747701128.189294  554071 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747701128.224559  554071 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747701128.224599  554071 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747701128.224601  554071 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747701128.224603  554071 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-20 08:32:08.231003: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "766a57eac9ffb5f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Data Preparation",
   "id": "adf62a5cc3f776da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:34:04.371153Z",
     "start_time": "2025-05-20T00:33:57.077192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a dataset\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"data/cub_200/images\",\n",
    "    labels='inferred',            # Automatically infer labels from subdirectory names\n",
    "    label_mode='int',             # 'int', 'categorical', or None\n",
    "    image_size=(224, 224),        # Resize images to this size\n",
    "    batch_size=64,                # Batch size\n",
    "    shuffle=True                  # Shuffle the data\n",
    ")"
   ],
   "id": "dc5d8e58196ac354",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11788 files belonging to 200 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747701243.079701  554071 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13553 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:34:06.935141Z",
     "start_time": "2025-05-20T00:34:06.692025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the dataset\n",
    "for images, labels in dataset.take(1):\n",
    "    print(images.shape)  # (64, 224, 224, 3)\n",
    "    print(labels)"
   ],
   "id": "f9978d60228b3a70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 224, 224, 3)\n",
      "tf.Tensor(\n",
      "[169 103 137 197 156  87 185 136 153 168   9  32  91 144   7  34  41 111\n",
      " 124 121  83 156 109 137 139  74  10   3 163 132  22 156 139 102  86 132\n",
      "  68 162  32  85  38  41  68  67 160 113 196   1 107 174  38  50  46  68\n",
      " 147 159 117 152 116 175 125  66 149  81], shape=(64,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 08:34:06.931866: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:34:10.233645Z",
     "start_time": "2025-05-20T00:34:10.213980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the augmentation layer\n",
    "data_augmentation = Sequential([\n",
    "    keras.layers.RandomFlip(\"horizontal\"),  # Random horizontal flipping\n",
    "    keras.layers.RandomZoom(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2)),  # Random scaling\n",
    "    keras.layers.RandomContrast(factor=0.2),  # Random contrast adjustment\n",
    "    keras.layers.RandomBrightness(factor=0.2)  # Random brightness adjustment\n",
    "])"
   ],
   "id": "b5b1c86c7f14b161",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:34:13.390586Z",
     "start_time": "2025-05-20T00:34:13.385356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply augmentations to a dataset\n",
    "def preprocess_dataset(image, label):\n",
    "    image = data_augmentation(image)\n",
    "\n",
    "    return image, label"
   ],
   "id": "a451ddc3c3d21c8e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:34:16.721543Z",
     "start_time": "2025-05-20T00:34:16.631242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the dataset\n",
    "augmented_dataset = dataset.map(preprocess_dataset, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ],
   "id": "73d37d560b713707",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:34:18.587339Z",
     "start_time": "2025-05-20T00:34:18.576304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get dataset size\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.5 * dataset_size)  # 50% for training\n",
    "val_size = dataset_size - train_size  # 50% for validation\n",
    "\n",
    "train_ds = dataset.take(train_size)  # First 50%\n",
    "val_ds = dataset.skip(train_size)  # Remaining 50%\n",
    "\n",
    "# Prepare datasets\n",
    "# train_ds = train_ds.shuffle(1000).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "# val_ds = val_ds.batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n"
   ],
   "id": "f5d2e59fd548a033",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:34:26.004121Z",
     "start_time": "2025-05-20T00:34:21.701467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for image, label in train_ds.take(1):\n",
    "    print(image.shape)  # Should be [batch_size, height, width, channels].\n",
    "    print(label.shape)  # Should be [batch_size]."
   ],
   "id": "db1d4146b568094e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 224, 224, 3)\n",
      "(64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 08:34:26.001702: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Creation",
   "id": "35452960bfe97464"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:34:31.619143Z",
     "start_time": "2025-05-20T00:34:29.383970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_model = keras.applications.ResNet101V2(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top."
   ],
   "id": "57d3865f902d8c8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:34:32.609104Z",
     "start_time": "2025-05-20T00:34:32.578267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Freeze the base_model\n",
    "base_model.trainable = True\n",
    "# Create new model on top\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "# Pre-trained weights requires that input be scaled\n",
    "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "# outputs: `(inputs * scale) + offset`\n",
    "# scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "# x = scale_layer(inputs)\n",
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(inputs, training=True)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "# x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "# outputs = keras.layers.Dense(1)(x)\n",
    "\n",
    "# base_model is running in inference mode here.\n",
    "outputs = keras.layers.Dense(200, activation=\"softmax\", name=\"Predictions\")(x)\n",
    "new_model = Model(inputs, outputs)\n",
    "\n",
    "new_model.summary(show_trainable=True)"
   ],
   "id": "4ff15f0be852595d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)               \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape         \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mTrai…\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ input_layer_2 (\u001B[38;5;33mInputLayer\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m224\u001B[0m, \u001B[38;5;34m224\u001B[0m, \u001B[38;5;34m3\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │   \u001B[1m-\u001B[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ resnet101v2 (\u001B[38;5;33mFunctional\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m2048\u001B[0m)    │ \u001B[38;5;34m42,626,560\u001B[0m │   \u001B[1;38;5;34mY\u001B[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ global_average_pooling2d    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)          │          \u001B[38;5;34m0\u001B[0m │   \u001B[1m-\u001B[0m   │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling2D\u001B[0m)    │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Predictions (\u001B[38;5;33mDense\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m200\u001B[0m)           │    \u001B[38;5;34m409,800\u001B[0m │   \u001B[1;38;5;34mY\u001B[0m   │\n",
       "└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                </span>┃<span style=\"font-weight: bold\"> Output Shape          </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Trai… </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ resnet101v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">42,626,560</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ global_average_pooling2d    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)    │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ Predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">409,800</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m43,036,360\u001B[0m (164.17 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,036,360</span> (164.17 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m42,938,696\u001B[0m (163.80 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,938,696</span> (163.80 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m97,664\u001B[0m (381.50 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,664</span> (381.50 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:34:40.079873Z",
     "start_time": "2025-05-20T00:34:40.077182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compile_model(model, lr=0.01, m=0.9, wd=0.001):\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=lr,\n",
    "                                                             decay_steps=940,\n",
    "                                                             decay_rate=0.1,)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=lr_schedule,\n",
    "                                      momentum=m,\n",
    "                                      weight_decay=wd),\n",
    "        # loss=keras.losses.BinaryCrossentropy,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        # metrics=[keras.metrics.BinaryAccuracy],\n",
    "        metrics=[\"sparse_categorical_accuracy\"]\n",
    "    )\n",
    "    return model"
   ],
   "id": "eb02032b6d9a0334",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Fitting",
   "id": "ce267ef04a30ccd8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:35:04.141805Z",
     "start_time": "2025-05-20T00:35:04.139227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "learning_rates = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "momentums = [0.0, 0.8, 0.9, 0.95, 0.99]"
   ],
   "id": "694cee99ed3b1e83",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T02:03:55.516558Z",
     "start_time": "2025-05-20T00:35:06.487717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare to log results\n",
    "results = []\n",
    "\n",
    "# Create directories for saving\n",
    "base_checkpoint_dir = \"checkpoints_momentum\"\n",
    "base_log_dir = \"logs_momentum\"\n",
    "os.makedirs(base_checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(base_log_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each momentum value\n",
    "for m in momentums:\n",
    "    print(f\"Training model with momentum: {m}\")\n",
    "    # Build the model\n",
    "    model = compile_model(new_model, m=m, wd=0.0)\n",
    "\n",
    "    # Define callbacks\n",
    "    checkpoint_dir = os.path.join(base_checkpoint_dir, f\"momentum_{m}\")\n",
    "    log_dir = os.path.join(base_log_dir, f\"momentum_{m}\")\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            # Path where to save the model\n",
    "            # The two parameters below mean that we will overwrite\n",
    "            # the current checkpoint if and only if\n",
    "            # the `val_loss` score has improved.\n",
    "            # The saved model name will include the current epoch.\n",
    "            filepath=os.path.join(checkpoint_dir,\n",
    "                                  \"model_epoch_{epoch:02d}_val_loss_{val_loss:.2f}.keras\"),\n",
    "            save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "            monitor=\"val_loss\", # Monitor validation loss\n",
    "            mode=\"min\",           # Save when val_loss decreases\n",
    "            verbose=1,),    # Print when saving\n",
    "\n",
    "        keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1,  # How often to log histogram visualizations\n",
    "        embeddings_freq=0,  # How often to log embedding visualizations\n",
    "        update_freq=\"epoch\",    # How often to write logs (default: once per epoch)\n",
    "        write_graph=True,      # Save the computational graph\n",
    "        write_images=True,      # Log model input images (if applicable)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_ds,\n",
    "                        epochs=30,\n",
    "                        # steps_per_epoch=94,\n",
    "                        validation_data=val_ds,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "    # Record results\n",
    "    best_val_loss = min(history.history[\"val_loss\"])\n",
    "    best_val_accuracy = max(history.history[\"val_sparse_categorical_accuracy\"])\n",
    "    results.append({\"momentum\": m, \"val_loss\": best_val_loss, \"val_accuracy\": best_val_accuracy})\n",
    "\n",
    "# Save results to a CSV file\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"momentum_tuning_results.csv\", index=False)\n",
    "print(\"Results saved to momentum_tuning_results.csv\")"
   ],
   "id": "1c9ba9d2679fc753",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with momentum: 0.0\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747701323.289459  556183 service.cc:152] XLA service 0x7f298c0030d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1747701323.289504  556183 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Ti SUPER, Compute Capability 8.9\n",
      "2025-05-20 08:35:23.948793: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1747701325.933254  556183 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-05-20 08:35:27.952105: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22697_0', 328 bytes spill stores, 328 bytes spill loads\n",
      "\n",
      "2025-05-20 08:35:28.040853: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22806', 248 bytes spill stores, 248 bytes spill loads\n",
      "\n",
      "2025-05-20 08:35:28.113898: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22697', 560 bytes spill stores, 560 bytes spill loads\n",
      "\n",
      "2025-05-20 08:35:28.142899: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22697', 2924 bytes spill stores, 2912 bytes spill loads\n",
      "\n",
      "2025-05-20 08:35:28.164849: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22697', 468 bytes spill stores, 468 bytes spill loads\n",
      "\n",
      "2025-05-20 08:35:28.384643: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22806', 1008 bytes spill stores, 1036 bytes spill loads\n",
      "\n",
      "2025-05-20 08:35:28.563338: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22806', 256 bytes spill stores, 256 bytes spill loads\n",
      "\n",
      "2025-05-20 08:35:28.579731: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22806', 88 bytes spill stores, 88 bytes spill loads\n",
      "\n",
      "2025-05-20 08:35:28.620609: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22883', 268 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "2025-05-20 08:35:29.010513: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22883', 276 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "2025-05-20 08:35:29.081180: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22883', 256 bytes spill stores, 256 bytes spill loads\n",
      "\n",
      "2025-05-20 08:35:29.091346: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22806', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2025-05-20 08:35:29.181947: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22883', 132 bytes spill stores, 132 bytes spill loads\n",
      "\n",
      "I0000 00:00:1747701345.865526  556183 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 5.3048 - sparse_categorical_accuracy: 0.0216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 08:36:13.436689: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2964', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-05-20 08:36:13.605162: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2964', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-05-20 08:36:13.774677: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2964', 120 bytes spill stores, 120 bytes spill loads\n",
      "\n",
      "2025-05-20 08:36:14.022364: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2964', 3972 bytes spill stores, 3952 bytes spill loads\n",
      "\n",
      "2025-05-20 08:36:14.083531: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2964', 1068 bytes spill stores, 1068 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 4.40653, saving model to checkpoints_momentum/momentum_0.0/model_epoch_01_val_loss_4.41.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m79s\u001B[0m 437ms/step - loss: 5.3018 - sparse_categorical_accuracy: 0.0220 - val_loss: 4.4065 - val_sparse_categorical_accuracy: 0.1031\n",
      "Epoch 2/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 3.5153 - sparse_categorical_accuracy: 0.3596\n",
      "Epoch 2: val_loss improved from 4.40653 to 3.06598, saving model to checkpoints_momentum/momentum_0.0/model_epoch_02_val_loss_3.07.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 348ms/step - loss: 3.5135 - sparse_categorical_accuracy: 0.3599 - val_loss: 3.0660 - val_sparse_categorical_accuracy: 0.2941\n",
      "Epoch 3/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 2.3262 - sparse_categorical_accuracy: 0.6664\n",
      "Epoch 3: val_loss improved from 3.06598 to 2.66759, saving model to checkpoints_momentum/momentum_0.0/model_epoch_03_val_loss_2.67.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 344ms/step - loss: 2.3252 - sparse_categorical_accuracy: 0.6665 - val_loss: 2.6676 - val_sparse_categorical_accuracy: 0.3886\n",
      "Epoch 4/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 1.5750 - sparse_categorical_accuracy: 0.8310\n",
      "Epoch 4: val_loss improved from 2.66759 to 2.51622, saving model to checkpoints_momentum/momentum_0.0/model_epoch_04_val_loss_2.52.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 344ms/step - loss: 1.5748 - sparse_categorical_accuracy: 0.8310 - val_loss: 2.5162 - val_sparse_categorical_accuracy: 0.4292\n",
      "Epoch 5/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 1.1395 - sparse_categorical_accuracy: 0.9049\n",
      "Epoch 5: val_loss improved from 2.51622 to 2.43391, saving model to checkpoints_momentum/momentum_0.0/model_epoch_05_val_loss_2.43.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 350ms/step - loss: 1.1396 - sparse_categorical_accuracy: 0.9048 - val_loss: 2.4339 - val_sparse_categorical_accuracy: 0.4559\n",
      "Epoch 6/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 0.8759 - sparse_categorical_accuracy: 0.9467\n",
      "Epoch 6: val_loss improved from 2.43391 to 2.38545, saving model to checkpoints_momentum/momentum_0.0/model_epoch_06_val_loss_2.39.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 351ms/step - loss: 0.8760 - sparse_categorical_accuracy: 0.9467 - val_loss: 2.3854 - val_sparse_categorical_accuracy: 0.4686\n",
      "Epoch 7/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 0.7265 - sparse_categorical_accuracy: 0.9592\n",
      "Epoch 7: val_loss improved from 2.38545 to 2.32853, saving model to checkpoints_momentum/momentum_0.0/model_epoch_07_val_loss_2.33.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 348ms/step - loss: 0.7265 - sparse_categorical_accuracy: 0.9591 - val_loss: 2.3285 - val_sparse_categorical_accuracy: 0.4773\n",
      "Epoch 8/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 0.6163 - sparse_categorical_accuracy: 0.9689\n",
      "Epoch 8: val_loss improved from 2.32853 to 2.28389, saving model to checkpoints_momentum/momentum_0.0/model_epoch_08_val_loss_2.28.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 343ms/step - loss: 0.6163 - sparse_categorical_accuracy: 0.9689 - val_loss: 2.2839 - val_sparse_categorical_accuracy: 0.4815\n",
      "Epoch 9/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 0.5537 - sparse_categorical_accuracy: 0.9736\n",
      "Epoch 9: val_loss improved from 2.28389 to 2.25717, saving model to checkpoints_momentum/momentum_0.0/model_epoch_09_val_loss_2.26.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 347ms/step - loss: 0.5537 - sparse_categorical_accuracy: 0.9736 - val_loss: 2.2572 - val_sparse_categorical_accuracy: 0.4868\n",
      "Epoch 10/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 0.4989 - sparse_categorical_accuracy: 0.9767\n",
      "Epoch 10: val_loss improved from 2.25717 to 2.23274, saving model to checkpoints_momentum/momentum_0.0/model_epoch_10_val_loss_2.23.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 347ms/step - loss: 0.4987 - sparse_categorical_accuracy: 0.9767 - val_loss: 2.2327 - val_sparse_categorical_accuracy: 0.4881\n",
      "Epoch 11/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 0.4529 - sparse_categorical_accuracy: 0.9774\n",
      "Epoch 11: val_loss improved from 2.23274 to 2.22119, saving model to checkpoints_momentum/momentum_0.0/model_epoch_11_val_loss_2.22.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 344ms/step - loss: 0.4529 - sparse_categorical_accuracy: 0.9775 - val_loss: 2.2212 - val_sparse_categorical_accuracy: 0.4900\n",
      "Epoch 12/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 0.4201 - sparse_categorical_accuracy: 0.9859\n",
      "Epoch 12: val_loss improved from 2.22119 to 2.21313, saving model to checkpoints_momentum/momentum_0.0/model_epoch_12_val_loss_2.21.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 343ms/step - loss: 0.4202 - sparse_categorical_accuracy: 0.9859 - val_loss: 2.2131 - val_sparse_categorical_accuracy: 0.4920\n",
      "Epoch 13/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 0.4156 - sparse_categorical_accuracy: 0.9830\n",
      "Epoch 13: val_loss improved from 2.21313 to 2.20489, saving model to checkpoints_momentum/momentum_0.0/model_epoch_13_val_loss_2.20.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 343ms/step - loss: 0.4156 - sparse_categorical_accuracy: 0.9831 - val_loss: 2.2049 - val_sparse_categorical_accuracy: 0.4920\n",
      "Epoch 14/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 0.3709 - sparse_categorical_accuracy: 0.9889\n",
      "Epoch 14: val_loss improved from 2.20489 to 2.19758, saving model to checkpoints_momentum/momentum_0.0/model_epoch_14_val_loss_2.20.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 341ms/step - loss: 0.3711 - sparse_categorical_accuracy: 0.9888 - val_loss: 2.1976 - val_sparse_categorical_accuracy: 0.4932\n",
      "Epoch 15/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 0.3677 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 15: val_loss improved from 2.19758 to 2.19255, saving model to checkpoints_momentum/momentum_0.0/model_epoch_15_val_loss_2.19.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 345ms/step - loss: 0.3679 - sparse_categorical_accuracy: 0.9896 - val_loss: 2.1925 - val_sparse_categorical_accuracy: 0.4941\n",
      "Epoch 16/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 0.3822 - sparse_categorical_accuracy: 0.9849\n",
      "Epoch 16: val_loss improved from 2.19255 to 2.17913, saving model to checkpoints_momentum/momentum_0.0/model_epoch_16_val_loss_2.18.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 348ms/step - loss: 0.3821 - sparse_categorical_accuracy: 0.9850 - val_loss: 2.1791 - val_sparse_categorical_accuracy: 0.4961\n",
      "Epoch 17/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 0.3521 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 17: val_loss did not improve from 2.17913\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 330ms/step - loss: 0.3523 - sparse_categorical_accuracy: 0.9887 - val_loss: 2.1811 - val_sparse_categorical_accuracy: 0.4961\n",
      "Epoch 18/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 0.3483 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 18: val_loss did not improve from 2.17913\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 329ms/step - loss: 0.3485 - sparse_categorical_accuracy: 0.9890 - val_loss: 2.1816 - val_sparse_categorical_accuracy: 0.4956\n",
      "Epoch 19/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 0.3650 - sparse_categorical_accuracy: 0.9877\n",
      "Epoch 19: val_loss improved from 2.17913 to 2.17565, saving model to checkpoints_momentum/momentum_0.0/model_epoch_19_val_loss_2.18.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 345ms/step - loss: 0.3649 - sparse_categorical_accuracy: 0.9877 - val_loss: 2.1757 - val_sparse_categorical_accuracy: 0.4958\n",
      "Epoch 20/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 0.3767 - sparse_categorical_accuracy: 0.9853\n",
      "Epoch 20: val_loss did not improve from 2.17565\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 331ms/step - loss: 0.3764 - sparse_categorical_accuracy: 0.9854 - val_loss: 2.1757 - val_sparse_categorical_accuracy: 0.4954\n",
      "Epoch 21/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 0.3475 - sparse_categorical_accuracy: 0.9916\n",
      "Epoch 21: val_loss did not improve from 2.17565\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 330ms/step - loss: 0.3476 - sparse_categorical_accuracy: 0.9915 - val_loss: 2.1782 - val_sparse_categorical_accuracy: 0.4947\n",
      "Epoch 22/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 0.3447 - sparse_categorical_accuracy: 0.9909\n",
      "Epoch 22: val_loss improved from 2.17565 to 2.17438, saving model to checkpoints_momentum/momentum_0.0/model_epoch_22_val_loss_2.17.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 344ms/step - loss: 0.3447 - sparse_categorical_accuracy: 0.9909 - val_loss: 2.1744 - val_sparse_categorical_accuracy: 0.4956\n",
      "Epoch 23/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 0.3330 - sparse_categorical_accuracy: 0.9921\n",
      "Epoch 23: val_loss improved from 2.17438 to 2.17125, saving model to checkpoints_momentum/momentum_0.0/model_epoch_23_val_loss_2.17.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 343ms/step - loss: 0.3332 - sparse_categorical_accuracy: 0.9920 - val_loss: 2.1713 - val_sparse_categorical_accuracy: 0.4963\n",
      "Epoch 24/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 0.3416 - sparse_categorical_accuracy: 0.9885\n",
      "Epoch 24: val_loss improved from 2.17125 to 2.16827, saving model to checkpoints_momentum/momentum_0.0/model_epoch_24_val_loss_2.17.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 344ms/step - loss: 0.3417 - sparse_categorical_accuracy: 0.9885 - val_loss: 2.1683 - val_sparse_categorical_accuracy: 0.4981\n",
      "Epoch 25/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 0.3501 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 25: val_loss did not improve from 2.16827\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 334ms/step - loss: 0.3501 - sparse_categorical_accuracy: 0.9888 - val_loss: 2.1712 - val_sparse_categorical_accuracy: 0.4954\n",
      "Epoch 26/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 0.3374 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 26: val_loss did not improve from 2.16827\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 333ms/step - loss: 0.3375 - sparse_categorical_accuracy: 0.9909 - val_loss: 2.1719 - val_sparse_categorical_accuracy: 0.4953\n",
      "Epoch 27/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 0.3318 - sparse_categorical_accuracy: 0.9924\n",
      "Epoch 27: val_loss improved from 2.16827 to 2.16740, saving model to checkpoints_momentum/momentum_0.0/model_epoch_27_val_loss_2.17.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 349ms/step - loss: 0.3320 - sparse_categorical_accuracy: 0.9924 - val_loss: 2.1674 - val_sparse_categorical_accuracy: 0.4963\n",
      "Epoch 28/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 0.3305 - sparse_categorical_accuracy: 0.9902\n",
      "Epoch 28: val_loss did not improve from 2.16740\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 332ms/step - loss: 0.3306 - sparse_categorical_accuracy: 0.9902 - val_loss: 2.1732 - val_sparse_categorical_accuracy: 0.4963\n",
      "Epoch 29/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - loss: 0.3520 - sparse_categorical_accuracy: 0.9872\n",
      "Epoch 29: val_loss did not improve from 2.16740\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 342ms/step - loss: 0.3520 - sparse_categorical_accuracy: 0.9872 - val_loss: 2.1717 - val_sparse_categorical_accuracy: 0.4963\n",
      "Epoch 30/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 0.3348 - sparse_categorical_accuracy: 0.9883\n",
      "Epoch 30: val_loss did not improve from 2.16740\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 329ms/step - loss: 0.3349 - sparse_categorical_accuracy: 0.9883 - val_loss: 2.1695 - val_sparse_categorical_accuracy: 0.4975\n",
      "Training model with momentum: 0.8\n",
      "Epoch 1/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 0.5883 - sparse_categorical_accuracy: 0.9240\n",
      "Epoch 1: val_loss improved from inf to 2.32768, saving model to checkpoints_momentum/momentum_0.8/model_epoch_01_val_loss_2.33.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m73s\u001B[0m 422ms/step - loss: 0.5906 - sparse_categorical_accuracy: 0.9232 - val_loss: 2.3277 - val_sparse_categorical_accuracy: 0.4237\n",
      "Epoch 2/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 0.4214 - sparse_categorical_accuracy: 0.9262\n",
      "Epoch 2: val_loss improved from 2.32768 to 1.88116, saving model to checkpoints_momentum/momentum_0.8/model_epoch_02_val_loss_1.88.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 360ms/step - loss: 0.4209 - sparse_categorical_accuracy: 0.9263 - val_loss: 1.8812 - val_sparse_categorical_accuracy: 0.5193\n",
      "Epoch 3/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 0.0939 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 3: val_loss improved from 1.88116 to 1.57391, saving model to checkpoints_momentum/momentum_0.8/model_epoch_03_val_loss_1.57.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 363ms/step - loss: 0.0938 - sparse_categorical_accuracy: 0.9899 - val_loss: 1.5739 - val_sparse_categorical_accuracy: 0.5953\n",
      "Epoch 4/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 0.0259 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 4: val_loss improved from 1.57391 to 1.56053, saving model to checkpoints_momentum/momentum_0.8/model_epoch_04_val_loss_1.56.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 361ms/step - loss: 0.0260 - sparse_categorical_accuracy: 0.9988 - val_loss: 1.5605 - val_sparse_categorical_accuracy: 0.5941\n",
      "Epoch 5/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 177ms/step - loss: 0.0237 - sparse_categorical_accuracy: 0.9972\n",
      "Epoch 5: val_loss improved from 1.56053 to 1.49739, saving model to checkpoints_momentum/momentum_0.8/model_epoch_05_val_loss_1.50.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 368ms/step - loss: 0.0237 - sparse_categorical_accuracy: 0.9972 - val_loss: 1.4974 - val_sparse_categorical_accuracy: 0.6124\n",
      "Epoch 6/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 174ms/step - loss: 0.0159 - sparse_categorical_accuracy: 0.9987\n",
      "Epoch 6: val_loss did not improve from 1.49739\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 335ms/step - loss: 0.0159 - sparse_categorical_accuracy: 0.9987 - val_loss: 1.4981 - val_sparse_categorical_accuracy: 0.6141\n",
      "Epoch 7/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 174ms/step - loss: 0.0168 - sparse_categorical_accuracy: 0.9991\n",
      "Epoch 7: val_loss improved from 1.49739 to 1.48972, saving model to checkpoints_momentum/momentum_0.8/model_epoch_07_val_loss_1.49.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 366ms/step - loss: 0.0168 - sparse_categorical_accuracy: 0.9991 - val_loss: 1.4897 - val_sparse_categorical_accuracy: 0.6137\n",
      "Epoch 8/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 0.0116 - sparse_categorical_accuracy: 0.9991\n",
      "Epoch 8: val_loss improved from 1.48972 to 1.48032, saving model to checkpoints_momentum/momentum_0.8/model_epoch_08_val_loss_1.48.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 360ms/step - loss: 0.0116 - sparse_categorical_accuracy: 0.9991 - val_loss: 1.4803 - val_sparse_categorical_accuracy: 0.6195\n",
      "Epoch 9/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 0.0118 - sparse_categorical_accuracy: 0.9994\n",
      "Epoch 9: val_loss improved from 1.48032 to 1.47783, saving model to checkpoints_momentum/momentum_0.8/model_epoch_09_val_loss_1.48.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 367ms/step - loss: 0.0118 - sparse_categorical_accuracy: 0.9994 - val_loss: 1.4778 - val_sparse_categorical_accuracy: 0.6202\n",
      "Epoch 10/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9994\n",
      "Epoch 10: val_loss did not improve from 1.47783\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 338ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9994 - val_loss: 1.4779 - val_sparse_categorical_accuracy: 0.6210\n",
      "Epoch 11/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9990\n",
      "Epoch 11: val_loss improved from 1.47783 to 1.47578, saving model to checkpoints_momentum/momentum_0.8/model_epoch_11_val_loss_1.48.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 365ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9990 - val_loss: 1.4758 - val_sparse_categorical_accuracy: 0.6195\n",
      "Epoch 12/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 0.0079 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 12: val_loss improved from 1.47578 to 1.47402, saving model to checkpoints_momentum/momentum_0.8/model_epoch_12_val_loss_1.47.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 362ms/step - loss: 0.0079 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4740 - val_sparse_categorical_accuracy: 0.6203\n",
      "Epoch 13/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9997\n",
      "Epoch 13: val_loss improved from 1.47402 to 1.47315, saving model to checkpoints_momentum/momentum_0.8/model_epoch_13_val_loss_1.47.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 362ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9997 - val_loss: 1.4732 - val_sparse_categorical_accuracy: 0.6208\n",
      "Epoch 14/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 0.0070 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 14: val_loss improved from 1.47315 to 1.47313, saving model to checkpoints_momentum/momentum_0.8/model_epoch_14_val_loss_1.47.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 360ms/step - loss: 0.0070 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4731 - val_sparse_categorical_accuracy: 0.6222\n",
      "Epoch 15/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9994\n",
      "Epoch 15: val_loss did not improve from 1.47313\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 324ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9994 - val_loss: 1.4736 - val_sparse_categorical_accuracy: 0.6222\n",
      "Epoch 16/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9995\n",
      "Epoch 16: val_loss did not improve from 1.47313\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 320ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9995 - val_loss: 1.4739 - val_sparse_categorical_accuracy: 0.6224\n",
      "Epoch 17/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9998\n",
      "Epoch 17: val_loss did not improve from 1.47313\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 322ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9998 - val_loss: 1.4739 - val_sparse_categorical_accuracy: 0.6220\n",
      "Epoch 18/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9996\n",
      "Epoch 18: val_loss did not improve from 1.47313\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 321ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9996 - val_loss: 1.4736 - val_sparse_categorical_accuracy: 0.6227\n",
      "Epoch 19/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 0.0083 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 19: val_loss did not improve from 1.47313\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 320ms/step - loss: 0.0083 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4741 - val_sparse_categorical_accuracy: 0.6217\n",
      "Epoch 20/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 176ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9997\n",
      "Epoch 20: val_loss did not improve from 1.47313\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 328ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9997 - val_loss: 1.4739 - val_sparse_categorical_accuracy: 0.6222\n",
      "Epoch 21/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 198ms/step - loss: 0.0077 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 21: val_loss did not improve from 1.47313\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 352ms/step - loss: 0.0077 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4732 - val_sparse_categorical_accuracy: 0.6224\n",
      "Epoch 22/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 178ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 22: val_loss did not improve from 1.47313\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 324ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9999 - val_loss: 1.4732 - val_sparse_categorical_accuracy: 0.6214\n",
      "Epoch 23/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 190ms/step - loss: 0.0115 - sparse_categorical_accuracy: 0.9985\n",
      "Epoch 23: val_loss did not improve from 1.47313\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 339ms/step - loss: 0.0115 - sparse_categorical_accuracy: 0.9985 - val_loss: 1.4736 - val_sparse_categorical_accuracy: 0.6220\n",
      "Epoch 24/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9995\n",
      "Epoch 24: val_loss improved from 1.47313 to 1.47218, saving model to checkpoints_momentum/momentum_0.8/model_epoch_24_val_loss_1.47.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 356ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9995 - val_loss: 1.4722 - val_sparse_categorical_accuracy: 0.6229\n",
      "Epoch 25/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 0.0069 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 25: val_loss did not improve from 1.47218\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 350ms/step - loss: 0.0070 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4738 - val_sparse_categorical_accuracy: 0.6222\n",
      "Epoch 26/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 26: val_loss did not improve from 1.47218\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 332ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9999 - val_loss: 1.4732 - val_sparse_categorical_accuracy: 0.6229\n",
      "Epoch 27/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 27: val_loss did not improve from 1.47218\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 336ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9999 - val_loss: 1.4735 - val_sparse_categorical_accuracy: 0.6239\n",
      "Epoch 28/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 191ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9995\n",
      "Epoch 28: val_loss did not improve from 1.47218\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 336ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9995 - val_loss: 1.4735 - val_sparse_categorical_accuracy: 0.6229\n",
      "Epoch 29/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 191ms/step - loss: 0.0070 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 29: val_loss did not improve from 1.47218\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 336ms/step - loss: 0.0070 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4733 - val_sparse_categorical_accuracy: 0.6229\n",
      "Epoch 30/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 188ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9991\n",
      "Epoch 30: val_loss did not improve from 1.47218\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 332ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9991 - val_loss: 1.4732 - val_sparse_categorical_accuracy: 0.6224\n",
      "Training model with momentum: 0.9\n",
      "Epoch 1/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9995\n",
      "Epoch 1: val_loss improved from inf to 1.49507, saving model to checkpoints_momentum/momentum_0.9/model_epoch_01_val_loss_1.50.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m74s\u001B[0m 422ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9995 - val_loss: 1.4951 - val_sparse_categorical_accuracy: 0.6207\n",
      "Epoch 2/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 2: val_loss did not improve from 1.49507\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 319ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9999 - val_loss: 1.4991 - val_sparse_categorical_accuracy: 0.6173\n",
      "Epoch 3/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9996\n",
      "Epoch 3: val_loss did not improve from 1.49507\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 324ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9996 - val_loss: 1.5015 - val_sparse_categorical_accuracy: 0.6163\n",
      "Epoch 4/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9995\n",
      "Epoch 4: val_loss improved from 1.49507 to 1.48777, saving model to checkpoints_momentum/momentum_0.9/model_epoch_04_val_loss_1.49.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 361ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9995 - val_loss: 1.4878 - val_sparse_categorical_accuracy: 0.6253\n",
      "Epoch 5/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9997\n",
      "Epoch 5: val_loss did not improve from 1.48777\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 334ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9997 - val_loss: 1.4898 - val_sparse_categorical_accuracy: 0.6239\n",
      "Epoch 6/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9997\n",
      "Epoch 6: val_loss improved from 1.48777 to 1.48350, saving model to checkpoints_momentum/momentum_0.9/model_epoch_06_val_loss_1.48.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 365ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9997 - val_loss: 1.4835 - val_sparse_categorical_accuracy: 0.6225\n",
      "Epoch 7/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 0.0026 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 7: val_loss improved from 1.48350 to 1.48228, saving model to checkpoints_momentum/momentum_0.9/model_epoch_07_val_loss_1.48.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 362ms/step - loss: 0.0026 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4823 - val_sparse_categorical_accuracy: 0.6237\n",
      "Epoch 8/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 0.0027 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 8: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 337ms/step - loss: 0.0027 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4827 - val_sparse_categorical_accuracy: 0.6232\n",
      "Epoch 9/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9996\n",
      "Epoch 9: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 335ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9996 - val_loss: 1.4831 - val_sparse_categorical_accuracy: 0.6258\n",
      "Epoch 10/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 10: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 322ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9999 - val_loss: 1.4840 - val_sparse_categorical_accuracy: 0.6241\n",
      "Epoch 11/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 192ms/step - loss: 0.0022 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 11: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 339ms/step - loss: 0.0022 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4841 - val_sparse_categorical_accuracy: 0.6239\n",
      "Epoch 12/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 179ms/step - loss: 0.0024 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 12: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 343ms/step - loss: 0.0024 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4839 - val_sparse_categorical_accuracy: 0.6237\n",
      "Epoch 13/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - loss: 0.0025 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 13: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 341ms/step - loss: 0.0025 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4848 - val_sparse_categorical_accuracy: 0.6237\n",
      "Epoch 14/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 176ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 14: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 335ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9999 - val_loss: 1.4844 - val_sparse_categorical_accuracy: 0.6232\n",
      "Epoch 15/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 175ms/step - loss: 0.0023 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 15: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 342ms/step - loss: 0.0023 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4854 - val_sparse_categorical_accuracy: 0.6232\n",
      "Epoch 16/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 0.0023 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 16: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 333ms/step - loss: 0.0023 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4853 - val_sparse_categorical_accuracy: 0.6231\n",
      "Epoch 17/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 177ms/step - loss: 0.0024 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 17: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 336ms/step - loss: 0.0024 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4849 - val_sparse_categorical_accuracy: 0.6232\n",
      "Epoch 18/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - loss: 0.0022 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 18: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 336ms/step - loss: 0.0022 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4845 - val_sparse_categorical_accuracy: 0.6236\n",
      "Epoch 19/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 174ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 19: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 332ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9999 - val_loss: 1.4841 - val_sparse_categorical_accuracy: 0.6237\n",
      "Epoch 20/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 174ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 20: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 337ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9999 - val_loss: 1.4844 - val_sparse_categorical_accuracy: 0.6241\n",
      "Epoch 21/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 175ms/step - loss: 0.0023 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 21: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 337ms/step - loss: 0.0023 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4843 - val_sparse_categorical_accuracy: 0.6242\n",
      "Epoch 22/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 174ms/step - loss: 0.0022 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 22: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 337ms/step - loss: 0.0022 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4846 - val_sparse_categorical_accuracy: 0.6232\n",
      "Epoch 23/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 174ms/step - loss: 0.0023 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 23: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 339ms/step - loss: 0.0023 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4842 - val_sparse_categorical_accuracy: 0.6241\n",
      "Epoch 24/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 174ms/step - loss: 0.0022 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 24: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 335ms/step - loss: 0.0022 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4836 - val_sparse_categorical_accuracy: 0.6229\n",
      "Epoch 25/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - loss: 0.0024 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 25: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 338ms/step - loss: 0.0024 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4846 - val_sparse_categorical_accuracy: 0.6231\n",
      "Epoch 26/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 177ms/step - loss: 0.0027 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 26: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 341ms/step - loss: 0.0027 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4845 - val_sparse_categorical_accuracy: 0.6234\n",
      "Epoch 27/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 27: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 337ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9999 - val_loss: 1.4845 - val_sparse_categorical_accuracy: 0.6236\n",
      "Epoch 28/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 174ms/step - loss: 0.0024 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 28: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 337ms/step - loss: 0.0024 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4843 - val_sparse_categorical_accuracy: 0.6224\n",
      "Epoch 29/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 0.0023 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 29: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 336ms/step - loss: 0.0023 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4840 - val_sparse_categorical_accuracy: 0.6234\n",
      "Epoch 30/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 0.0028 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 30: val_loss did not improve from 1.48228\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 336ms/step - loss: 0.0028 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4845 - val_sparse_categorical_accuracy: 0.6239\n",
      "Training model with momentum: 0.95\n",
      "Epoch 1/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 1: val_loss improved from inf to 1.60242, saving model to checkpoints_momentum/momentum_0.95/model_epoch_01_val_loss_1.60.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m74s\u001B[0m 428ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9999 - val_loss: 1.6024 - val_sparse_categorical_accuracy: 0.6049\n",
      "Epoch 2/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 188ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9995\n",
      "Epoch 2: val_loss did not improve from 1.60242\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 339ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9995 - val_loss: 1.7286 - val_sparse_categorical_accuracy: 0.5734\n",
      "Epoch 3/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 0.0153 - sparse_categorical_accuracy: 0.9983\n",
      "Epoch 3: val_loss did not improve from 1.60242\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 342ms/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9983 - val_loss: 2.0060 - val_sparse_categorical_accuracy: 0.5168\n",
      "Epoch 4/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 0.0490 - sparse_categorical_accuracy: 0.9920\n",
      "Epoch 4: val_loss did not improve from 1.60242\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 336ms/step - loss: 0.0491 - sparse_categorical_accuracy: 0.9920 - val_loss: 1.9805 - val_sparse_categorical_accuracy: 0.5337\n",
      "Epoch 5/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 189ms/step - loss: 0.0807 - sparse_categorical_accuracy: 0.9839\n",
      "Epoch 5: val_loss did not improve from 1.60242\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 341ms/step - loss: 0.0808 - sparse_categorical_accuracy: 0.9838 - val_loss: 2.3067 - val_sparse_categorical_accuracy: 0.4875\n",
      "Epoch 6/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 0.0672 - sparse_categorical_accuracy: 0.9903\n",
      "Epoch 6: val_loss did not improve from 1.60242\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 334ms/step - loss: 0.0671 - sparse_categorical_accuracy: 0.9903 - val_loss: 1.9449 - val_sparse_categorical_accuracy: 0.5458\n",
      "Epoch 7/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 192ms/step - loss: 0.0209 - sparse_categorical_accuracy: 0.9987\n",
      "Epoch 7: val_loss did not improve from 1.60242\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 341ms/step - loss: 0.0209 - sparse_categorical_accuracy: 0.9987 - val_loss: 1.7010 - val_sparse_categorical_accuracy: 0.5910\n",
      "Epoch 8/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 193ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9991\n",
      "Epoch 8: val_loss did not improve from 1.60242\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 340ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9991 - val_loss: 1.6670 - val_sparse_categorical_accuracy: 0.5990\n",
      "Epoch 9/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 191ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9994\n",
      "Epoch 9: val_loss did not improve from 1.60242\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 342ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9994 - val_loss: 1.6139 - val_sparse_categorical_accuracy: 0.6119\n",
      "Epoch 10/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9995\n",
      "Epoch 10: val_loss improved from 1.60242 to 1.59655, saving model to checkpoints_momentum/momentum_0.95/model_epoch_10_val_loss_1.60.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 364ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9995 - val_loss: 1.5965 - val_sparse_categorical_accuracy: 0.6164\n",
      "Epoch 11/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 188ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9986\n",
      "Epoch 11: val_loss improved from 1.59655 to 1.59528, saving model to checkpoints_momentum/momentum_0.95/model_epoch_11_val_loss_1.60.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 363ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9986 - val_loss: 1.5953 - val_sparse_categorical_accuracy: 0.6164\n",
      "Epoch 12/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9998\n",
      "Epoch 12: val_loss improved from 1.59528 to 1.59096, saving model to checkpoints_momentum/momentum_0.95/model_epoch_12_val_loss_1.59.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 360ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9998 - val_loss: 1.5910 - val_sparse_categorical_accuracy: 0.6190\n",
      "Epoch 13/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - loss: 0.0017 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 13: val_loss improved from 1.59096 to 1.58939, saving model to checkpoints_momentum/momentum_0.95/model_epoch_13_val_loss_1.59.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 374ms/step - loss: 0.0017 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5894 - val_sparse_categorical_accuracy: 0.6188\n",
      "Epoch 14/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 0.0019 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 14: val_loss improved from 1.58939 to 1.58782, saving model to checkpoints_momentum/momentum_0.95/model_epoch_14_val_loss_1.59.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 345ms/step - loss: 0.0019 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5878 - val_sparse_categorical_accuracy: 0.6195\n",
      "Epoch 15/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 195ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 15: val_loss improved from 1.58782 to 1.58667, saving model to checkpoints_momentum/momentum_0.95/model_epoch_15_val_loss_1.59.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 369ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9999 - val_loss: 1.5867 - val_sparse_categorical_accuracy: 0.6195\n",
      "Epoch 16/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 16: val_loss improved from 1.58667 to 1.58557, saving model to checkpoints_momentum/momentum_0.95/model_epoch_16_val_loss_1.59.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 361ms/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5856 - val_sparse_categorical_accuracy: 0.6203\n",
      "Epoch 17/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 188ms/step - loss: 0.0020 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 17: val_loss improved from 1.58557 to 1.58472, saving model to checkpoints_momentum/momentum_0.95/model_epoch_17_val_loss_1.58.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 370ms/step - loss: 0.0020 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5847 - val_sparse_categorical_accuracy: 0.6198\n",
      "Epoch 18/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 178ms/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 18: val_loss did not improve from 1.58472\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 328ms/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5853 - val_sparse_categorical_accuracy: 0.6192\n",
      "Epoch 19/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 19: val_loss did not improve from 1.58472\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 320ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9999 - val_loss: 1.5856 - val_sparse_categorical_accuracy: 0.6192\n",
      "Epoch 20/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 20: val_loss did not improve from 1.58472\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 320ms/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5858 - val_sparse_categorical_accuracy: 0.6190\n",
      "Epoch 21/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 21: val_loss did not improve from 1.58472\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 320ms/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5856 - val_sparse_categorical_accuracy: 0.6183\n",
      "Epoch 22/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 174ms/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 22: val_loss did not improve from 1.58472\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 320ms/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5853 - val_sparse_categorical_accuracy: 0.6190\n",
      "Epoch 23/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - loss: 0.0017 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 23: val_loss did not improve from 1.58472\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 318ms/step - loss: 0.0017 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5856 - val_sparse_categorical_accuracy: 0.6202\n",
      "Epoch 24/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 24: val_loss improved from 1.58472 to 1.58432, saving model to checkpoints_momentum/momentum_0.95/model_epoch_24_val_loss_1.58.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 359ms/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5843 - val_sparse_categorical_accuracy: 0.6197\n",
      "Epoch 25/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 25: val_loss improved from 1.58432 to 1.58426, saving model to checkpoints_momentum/momentum_0.95/model_epoch_25_val_loss_1.58.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 360ms/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5843 - val_sparse_categorical_accuracy: 0.6195\n",
      "Epoch 26/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 26: val_loss did not improve from 1.58426\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 334ms/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5856 - val_sparse_categorical_accuracy: 0.6193\n",
      "Epoch 27/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9998\n",
      "Epoch 27: val_loss did not improve from 1.58426\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 346ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9998 - val_loss: 1.5843 - val_sparse_categorical_accuracy: 0.6193\n",
      "Epoch 28/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 0.0017 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 28: val_loss did not improve from 1.58426\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 339ms/step - loss: 0.0017 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5846 - val_sparse_categorical_accuracy: 0.6198\n",
      "Epoch 29/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 0.0020 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 29: val_loss did not improve from 1.58426\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 335ms/step - loss: 0.0020 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5851 - val_sparse_categorical_accuracy: 0.6190\n",
      "Epoch 30/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 30: val_loss did not improve from 1.58426\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 332ms/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5844 - val_sparse_categorical_accuracy: 0.6193\n",
      "Training model with momentum: 0.99\n",
      "Epoch 1/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9998\n",
      "Epoch 1: val_loss improved from inf to 1.67995, saving model to checkpoints_momentum/momentum_0.99/model_epoch_01_val_loss_1.68.keras\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 426ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9998 - val_loss: 1.6799 - val_sparse_categorical_accuracy: 0.6069\n",
      "Epoch 2/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9987\n",
      "Epoch 2: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 341ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9986 - val_loss: 2.7644 - val_sparse_categorical_accuracy: 0.4239\n",
      "Epoch 3/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 1.2914 - sparse_categorical_accuracy: 0.6928\n",
      "Epoch 3: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 340ms/step - loss: 1.3043 - sparse_categorical_accuracy: 0.6900 - val_loss: 3692.2808 - val_sparse_categorical_accuracy: 0.0053\n",
      "Epoch 4/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 3.4161 - sparse_categorical_accuracy: 0.2264\n",
      "Epoch 4: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 338ms/step - loss: 3.4151 - sparse_categorical_accuracy: 0.2265 - val_loss: 1074.4935 - val_sparse_categorical_accuracy: 0.0054\n",
      "Epoch 5/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 2.5001 - sparse_categorical_accuracy: 0.3621\n",
      "Epoch 5: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 342ms/step - loss: 2.4982 - sparse_categorical_accuracy: 0.3625 - val_loss: 9.7573 - val_sparse_categorical_accuracy: 0.0064\n",
      "Epoch 6/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 1.4927 - sparse_categorical_accuracy: 0.5705\n",
      "Epoch 6: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 326ms/step - loss: 1.4926 - sparse_categorical_accuracy: 0.5707 - val_loss: 7.2551 - val_sparse_categorical_accuracy: 0.1136\n",
      "Epoch 7/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 0.9472 - sparse_categorical_accuracy: 0.7304\n",
      "Epoch 7: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 338ms/step - loss: 0.9465 - sparse_categorical_accuracy: 0.7305 - val_loss: 3.8762 - val_sparse_categorical_accuracy: 0.2758\n",
      "Epoch 8/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 0.4882 - sparse_categorical_accuracy: 0.8594\n",
      "Epoch 8: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 340ms/step - loss: 0.4878 - sparse_categorical_accuracy: 0.8595 - val_loss: 2.9441 - val_sparse_categorical_accuracy: 0.3854\n",
      "Epoch 9/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 0.2215 - sparse_categorical_accuracy: 0.9421\n",
      "Epoch 9: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 318ms/step - loss: 0.2215 - sparse_categorical_accuracy: 0.9421 - val_loss: 2.9231 - val_sparse_categorical_accuracy: 0.3912\n",
      "Epoch 10/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 175ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9768\n",
      "Epoch 10: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 329ms/step - loss: 0.1191 - sparse_categorical_accuracy: 0.9768 - val_loss: 2.7448 - val_sparse_categorical_accuracy: 0.4241\n",
      "Epoch 11/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 0.0481 - sparse_categorical_accuracy: 0.9954\n",
      "Epoch 11: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 318ms/step - loss: 0.0483 - sparse_categorical_accuracy: 0.9954 - val_loss: 2.5619 - val_sparse_categorical_accuracy: 0.4658\n",
      "Epoch 12/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 0.0326 - sparse_categorical_accuracy: 0.9972\n",
      "Epoch 12: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 331ms/step - loss: 0.0326 - sparse_categorical_accuracy: 0.9971 - val_loss: 2.5228 - val_sparse_categorical_accuracy: 0.4819\n",
      "Epoch 13/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 0.0268 - sparse_categorical_accuracy: 0.9979\n",
      "Epoch 13: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 331ms/step - loss: 0.0268 - sparse_categorical_accuracy: 0.9979 - val_loss: 2.5166 - val_sparse_categorical_accuracy: 0.4888\n",
      "Epoch 14/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 0.0193 - sparse_categorical_accuracy: 0.9983\n",
      "Epoch 14: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 330ms/step - loss: 0.0193 - sparse_categorical_accuracy: 0.9983 - val_loss: 2.5192 - val_sparse_categorical_accuracy: 0.4917\n",
      "Epoch 15/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 0.0129 - sparse_categorical_accuracy: 0.9986\n",
      "Epoch 15: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 331ms/step - loss: 0.0130 - sparse_categorical_accuracy: 0.9986 - val_loss: 2.5198 - val_sparse_categorical_accuracy: 0.4910\n",
      "Epoch 16/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9996\n",
      "Epoch 16: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 330ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9996 - val_loss: 2.5205 - val_sparse_categorical_accuracy: 0.4920\n",
      "Epoch 17/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 0.0123 - sparse_categorical_accuracy: 0.9992\n",
      "Epoch 17: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 332ms/step - loss: 0.0123 - sparse_categorical_accuracy: 0.9992 - val_loss: 2.5201 - val_sparse_categorical_accuracy: 0.4929\n",
      "Epoch 18/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 0.0105 - sparse_categorical_accuracy: 0.9992\n",
      "Epoch 18: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 332ms/step - loss: 0.0105 - sparse_categorical_accuracy: 0.9992 - val_loss: 2.5155 - val_sparse_categorical_accuracy: 0.4944\n",
      "Epoch 19/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 175ms/step - loss: 0.0107 - sparse_categorical_accuracy: 0.9991\n",
      "Epoch 19: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 335ms/step - loss: 0.0108 - sparse_categorical_accuracy: 0.9991 - val_loss: 2.5143 - val_sparse_categorical_accuracy: 0.4949\n",
      "Epoch 20/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 0.0127 - sparse_categorical_accuracy: 0.9988\n",
      "Epoch 20: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 333ms/step - loss: 0.0127 - sparse_categorical_accuracy: 0.9988 - val_loss: 2.5166 - val_sparse_categorical_accuracy: 0.4941\n",
      "Epoch 21/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9991\n",
      "Epoch 21: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 334ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9991 - val_loss: 2.5186 - val_sparse_categorical_accuracy: 0.4942\n",
      "Epoch 22/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 22: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 333ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.5185 - val_sparse_categorical_accuracy: 0.4944\n",
      "Epoch 23/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9992\n",
      "Epoch 23: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 333ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9992 - val_loss: 2.5165 - val_sparse_categorical_accuracy: 0.4934\n",
      "Epoch 24/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 0.0109 - sparse_categorical_accuracy: 0.9991\n",
      "Epoch 24: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 332ms/step - loss: 0.0109 - sparse_categorical_accuracy: 0.9991 - val_loss: 2.5188 - val_sparse_categorical_accuracy: 0.4951\n",
      "Epoch 25/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 25: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 331ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.5161 - val_sparse_categorical_accuracy: 0.4963\n",
      "Epoch 26/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9989\n",
      "Epoch 26: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 334ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9989 - val_loss: 2.5160 - val_sparse_categorical_accuracy: 0.4953\n",
      "Epoch 27/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 0.0081 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 27: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 325ms/step - loss: 0.0081 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.5162 - val_sparse_categorical_accuracy: 0.4946\n",
      "Epoch 28/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9999\n",
      "Epoch 28: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 336ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.5180 - val_sparse_categorical_accuracy: 0.4946\n",
      "Epoch 29/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9991\n",
      "Epoch 29: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 329ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9991 - val_loss: 2.5171 - val_sparse_categorical_accuracy: 0.4949\n",
      "Epoch 30/30\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9992\n",
      "Epoch 30: val_loss did not improve from 1.67995\n",
      "\u001B[1m92/92\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 330ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9992 - val_loss: 2.5198 - val_sparse_categorical_accuracy: 0.4946\n",
      "Results saved to momentum_tuning_results.csv\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T02:56:50.220661Z",
     "start_time": "2025-05-20T02:56:50.207577Z"
    }
   },
   "cell_type": "code",
   "source": "results_df",
   "id": "a106a1b8dad6ec62",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   momentum  val_loss  val_accuracy\n",
       "0      0.00  2.167397      0.498136\n",
       "1      0.80  1.472176      0.623898\n",
       "2      0.90  1.482276      0.625763\n",
       "3      0.95  1.584263      0.620339\n",
       "4      0.99  1.679947      0.606949"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>momentum</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.167397</td>\n",
       "      <td>0.498136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>1.472176</td>\n",
       "      <td>0.623898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.90</td>\n",
       "      <td>1.482276</td>\n",
       "      <td>0.625763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1.584263</td>\n",
       "      <td>0.620339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.679947</td>\n",
       "      <td>0.606949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T22:32:13.211067Z",
     "start_time": "2025-05-19T22:32:13.204417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_loss_accuracy(history):\n",
    "    historydf = pd.DataFrame(history.history, index=history.epoch)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    historydf.plot(ylim=(0, max(1, historydf.values.max())))\n",
    "    loss = history.history['loss'][-1]\n",
    "    acc = history.history['sparse_categorical_accuracy'][-1]\n",
    "    plt.title('Loss: %.3f, Accuracy: %.3f' % (loss, acc))"
   ],
   "id": "e654873aac8a2cfb",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T22:29:42.001150Z",
     "start_time": "2025-05-19T22:29:41.997451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute Top-1 Validation Error\n",
    "val_accuracy = history.history['val_sparse_categorical_accuracy']\n",
    "val_error = [1 - acc for acc in val_accuracy]\n",
    "\n",
    "min_val_error = min(val_error)\n",
    "best_epoch = val_error.index(min_val_error) + 1\n",
    "\n",
    "print(f\"Minimal Top-1 Validation Error: {min_val_error:.4f} at Epoch {best_epoch}\")"
   ],
   "id": "291f8477d14bb483",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal Top-1 Validation Error: 0.3783 at Epoch 1\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:24:24.650132Z",
     "start_time": "2025-05-20T05:24:24.629776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plot Validation Error\n",
    "plt.plot(range(1, len(val_error) + 1), val_error, label='Top-1 Validation Error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "42143be05c893866",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Plot Validation Error\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m plt.plot(\u001B[38;5;28mrange\u001B[39m(\u001B[32m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(\u001B[43mval_error\u001B[49m) + \u001B[32m1\u001B[39m), val_error, label=\u001B[33m'\u001B[39m\u001B[33mTop-1 Validation Error\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      3\u001B[39m plt.xlabel(\u001B[33m'\u001B[39m\u001B[33mEpochs\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      4\u001B[39m plt.ylabel(\u001B[33m'\u001B[39m\u001B[33mError\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'val_error' is not defined"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T05:24:15.142542Z",
     "start_time": "2025-05-20T05:24:14.091352Z"
    }
   },
   "cell_type": "code",
   "source": "plot_loss_accuracy(history)",
   "id": "3d3cf2ae7851e01b",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_loss_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mplot_loss_accuracy\u001B[49m(history)\n",
      "\u001B[31mNameError\u001B[39m: name 'plot_loss_accuracy' is not defined"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
