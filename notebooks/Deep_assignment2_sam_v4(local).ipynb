{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W05MsBkD21wo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.applications import ResNet101V2\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6gIym49BAFuR",
        "outputId": "a960d72c-72a9-4ee8-b1f7-d916a4fbea70"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>file_path</th>\n",
              "      <th>class_id</th>\n",
              "      <th>is_train</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   image_id                                          file_path  class_id  \\\n",
              "0         1  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
              "1         2  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
              "2         3  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
              "3         4  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
              "4         5  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
              "\n",
              "   is_train  \n",
              "0         0  \n",
              "1         1  \n",
              "2         0  \n",
              "3         1  \n",
              "4         1  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Set base path for uploaded files\n",
        "base_path = \"/home/samng/MADS-wsl/Deep_learning/Assignment2/Bird dataset/CUB_200_2011/\"\n",
        "\n",
        "image_dir = f\"{base_path}images\"  # folder containing all class folders and images\n",
        "\n",
        "\n",
        "# Load metadata files\n",
        "images_df = pd.read_csv(base_path + \"images.txt\", sep=\" \", header=None, names=[\"image_id\", \"file_path\"])\n",
        "labels_df = pd.read_csv(base_path + \"image_class_labels.txt\", sep=\" \", header=None, names=[\"image_id\", \"class_id\"])\n",
        "split_df = pd.read_csv(base_path + \"train_test_split.txt\", sep=\" \", header=None, names=[\"image_id\", \"is_train\"])\n",
        "\n",
        "# Merge into one master DataFrame\n",
        "metadata_df = images_df.merge(labels_df, on=\"image_id\")\n",
        "metadata_df = metadata_df.merge(split_df, on=\"image_id\")\n",
        "\n",
        "# Preview result\n",
        "metadata_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "EJ6WnrAMMPT5",
        "outputId": "32c94faa-4d8b-4aa1-ae27-f47eea3129d2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>file_path</th>\n",
              "      <th>class_id</th>\n",
              "      <th>is_train</th>\n",
              "      <th>full_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>/home/samng/MADS-wsl/Deep_learning/Assignment2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>/home/samng/MADS-wsl/Deep_learning/Assignment2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>/home/samng/MADS-wsl/Deep_learning/Assignment2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>/home/samng/MADS-wsl/Deep_learning/Assignment2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>/home/samng/MADS-wsl/Deep_learning/Assignment2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   image_id                                          file_path  class_id  \\\n",
              "0         1  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
              "1         2  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
              "2         3  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
              "3         4  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
              "4         5  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
              "\n",
              "   is_train                                          full_path  \n",
              "0         0  /home/samng/MADS-wsl/Deep_learning/Assignment2...  \n",
              "1         1  /home/samng/MADS-wsl/Deep_learning/Assignment2...  \n",
              "2         0  /home/samng/MADS-wsl/Deep_learning/Assignment2...  \n",
              "3         1  /home/samng/MADS-wsl/Deep_learning/Assignment2...  \n",
              "4         1  /home/samng/MADS-wsl/Deep_learning/Assignment2...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Step 5: Add full image path\n",
        "metadata_df[\"full_path\"] = metadata_df[\"file_path\"].apply(lambda x: f\"{image_dir}/{x}\")\n",
        "\n",
        "# Step 6: Split into train and test sets\n",
        "train_df  = metadata_df[metadata_df[\"is_train\"] == 1].reset_index(drop=True)\n",
        "test_df  = metadata_df[metadata_df[\"is_train\"] == 0].reset_index(drop=True)\n",
        "\n",
        "metadata_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZYL016m7M2L",
        "outputId": "b239b44a-b36b-43f9-bab4-dc622e82ca4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set size: 5994\n",
            "Test set size: 5794\n"
          ]
        }
      ],
      "source": [
        "print(\"Train set size:\", len(train_df ))\n",
        "print(\"Test set size:\", len(test_df ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "671om77Ur7mF"
      },
      "outputs": [],
      "source": [
        "# Step 4.1: Set hyperparameters for the experiment\n",
        "learning_rate = 0.01\n",
        "momentum = 0.0\n",
        "weight_decay = 0.0001  # Not used directly unless you apply kernel_regularizer\n",
        "num_epochs = 30    # paper used 300 (fine tuning)\n",
        "batch_size = 32   # paper use 256 (colab out of memory when using 256)\n",
        "\n",
        "# steps_per_epoch = 3 # Not use here , only used for small trtain set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "G7vP-Ac0Qn8b"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Step 2A: Image loading and preprocessing function\n",
        "def load_and_preprocess_image(path, label):\n",
        "    # This line loads the image from Google Drive\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "    # Resize (shorter side = 256) — using resize_with_pad to preserve aspect\n",
        "    image = tf.image.resize_with_pad(image, target_height=256, target_width=256)\n",
        "\n",
        "    # Random crop to 224×224\n",
        "    image = tf.image.random_crop(image, size=[224, 224, 3])\n",
        "\n",
        "    # Data augmentation (to match paper)\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "\n",
        "    # Normalize with ImageNet mean/std\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    image = (image - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
        "\n",
        "    return image, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Qkgp1vk7aDZU"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_image_val(path, label):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "    # Resize and center crop\n",
        "    image = tf.image.resize_with_pad(image, 256, 256)\n",
        "    image = tf.image.central_crop(image, central_fraction=0.875)  # ~224/256 = 0.875\n",
        "\n",
        "    # Normalize\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    image = (image - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
        "\n",
        "    return image, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "_tGx_Z4PS1Dm"
      },
      "outputs": [],
      "source": [
        "# Convert Pandas train_df  into TensorFlow dataset\n",
        "# Step 2B: Create TensorFlow dataset from train_df\n",
        "train_paths = train_df [\"full_path\"].tolist()\n",
        "train_labels = train_df [\"class_id\"].astype(int) - 1  # shift to 0-based index\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
        "train_dataset = train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Add caching and prefetching to optimize performance\n",
        "train_dataset = train_dataset.cache().shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "DrCrofaJaElu"
      },
      "outputs": [],
      "source": [
        "test_paths = test_df [\"full_path\"].tolist()\n",
        "test_labels = test_df [\"class_id\"].astype(int) - 1\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
        "test_dataset = test_dataset.map(load_and_preprocess_image_val, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "BmWPq0kQcOlt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-17 22:26:27.114063: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Load and modify pretrained ResNet-101-V2\n",
        "\n",
        "# Load base model\n",
        "base_model = ResNet101V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3), pooling='avg')\n",
        "\n",
        "x = layers.Dense(\n",
        "    200,\n",
        "    activation='softmax',\n",
        "    kernel_regularizer=regularizers.l2(weight_decay)  # L2 = weight decay\n",
        ")(base_model.output)\n",
        "\n",
        "model = models.Model(inputs=base_model.input, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "H3khO6KIcRLx"
      },
      "outputs": [],
      "source": [
        "# Step 5: Compile the model with optimizer and hyperparameters\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4i7jt-Uuas4",
        "outputId": "0de04566-c7a2-4e79-e44e-4a4738d9af1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 356ms/step - accuracy: 0.1176 - loss: 4.5853 - val_accuracy: 0.1205 - val_loss: 4.9322\n",
            "Epoch 2/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 276ms/step - accuracy: 0.4907 - loss: 2.4277 - val_accuracy: 0.2901 - val_loss: 3.1002\n",
            "Epoch 3/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 288ms/step - accuracy: 0.7696 - loss: 1.2207 - val_accuracy: 0.4360 - val_loss: 2.2894\n",
            "Epoch 4/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 279ms/step - accuracy: 0.9182 - loss: 0.6114 - val_accuracy: 0.4676 - val_loss: 2.1550\n",
            "Epoch 5/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 285ms/step - accuracy: 0.9777 - loss: 0.3014 - val_accuracy: 0.5136 - val_loss: 1.9519\n",
            "Epoch 6/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 279ms/step - accuracy: 0.9945 - loss: 0.1838 - val_accuracy: 0.5381 - val_loss: 1.8487\n",
            "Epoch 7/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 290ms/step - accuracy: 0.9962 - loss: 0.1277 - val_accuracy: 0.5532 - val_loss: 1.7874\n",
            "Epoch 8/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 292ms/step - accuracy: 0.9988 - loss: 0.0947 - val_accuracy: 0.5542 - val_loss: 1.8101\n",
            "Epoch 9/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 286ms/step - accuracy: 0.9999 - loss: 0.0790 - val_accuracy: 0.5575 - val_loss: 1.7808\n",
            "Epoch 10/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 288ms/step - accuracy: 1.0000 - loss: 0.0698 - val_accuracy: 0.5654 - val_loss: 1.7542\n",
            "Epoch 11/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 289ms/step - accuracy: 0.9998 - loss: 0.0634 - val_accuracy: 0.5590 - val_loss: 1.7834\n",
            "Epoch 12/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 289ms/step - accuracy: 1.0000 - loss: 0.0600 - val_accuracy: 0.5623 - val_loss: 1.7632\n",
            "Epoch 13/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 288ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.5682 - val_loss: 1.7415\n",
            "Epoch 14/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 285ms/step - accuracy: 1.0000 - loss: 0.0538 - val_accuracy: 0.5753 - val_loss: 1.7382\n",
            "Epoch 15/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 293ms/step - accuracy: 1.0000 - loss: 0.0535 - val_accuracy: 0.5780 - val_loss: 1.7349\n",
            "Epoch 16/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 285ms/step - accuracy: 1.0000 - loss: 0.0510 - val_accuracy: 0.5765 - val_loss: 1.7389\n",
            "Epoch 17/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 292ms/step - accuracy: 1.0000 - loss: 0.0500 - val_accuracy: 0.5765 - val_loss: 1.7463\n",
            "Epoch 18/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 290ms/step - accuracy: 1.0000 - loss: 0.0492 - val_accuracy: 0.5753 - val_loss: 1.7465\n",
            "Epoch 19/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 288ms/step - accuracy: 0.9998 - loss: 0.0479 - val_accuracy: 0.5704 - val_loss: 1.7834\n",
            "Epoch 20/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 289ms/step - accuracy: 1.0000 - loss: 0.0479 - val_accuracy: 0.5730 - val_loss: 1.7673\n",
            "Epoch 21/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 276ms/step - accuracy: 1.0000 - loss: 0.0473 - val_accuracy: 0.5747 - val_loss: 1.7596\n",
            "Epoch 22/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 284ms/step - accuracy: 1.0000 - loss: 0.0461 - val_accuracy: 0.5749 - val_loss: 1.7601\n",
            "Epoch 23/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 290ms/step - accuracy: 1.0000 - loss: 0.0460 - val_accuracy: 0.5771 - val_loss: 1.7556\n",
            "Epoch 24/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 280ms/step - accuracy: 1.0000 - loss: 0.0449 - val_accuracy: 0.5775 - val_loss: 1.7548\n",
            "Epoch 25/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 286ms/step - accuracy: 1.0000 - loss: 0.0443 - val_accuracy: 0.5784 - val_loss: 1.7532\n",
            "Epoch 26/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 281ms/step - accuracy: 1.0000 - loss: 0.0443 - val_accuracy: 0.5742 - val_loss: 1.7706\n",
            "Epoch 27/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 293ms/step - accuracy: 1.0000 - loss: 0.0441 - val_accuracy: 0.5790 - val_loss: 1.7571\n",
            "Epoch 28/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 292ms/step - accuracy: 1.0000 - loss: 0.0437 - val_accuracy: 0.5683 - val_loss: 1.7945\n",
            "Epoch 29/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 293ms/step - accuracy: 1.0000 - loss: 0.0437 - val_accuracy: 0.5808 - val_loss: 1.7717\n",
            "Epoch 30/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 289ms/step - accuracy: 1.0000 - loss: 0.0440 - val_accuracy: 0.5789 - val_loss: 1.7741\n",
            "Time spent: 1648.5821735858917 seconds\n"
          ]
        }
      ],
      "source": [
        "# Skip for now: full set of images\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# Train model\n",
        "training_metrics = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data= test_dataset,\n",
        "    epochs= num_epochs,\n",
        "    # steps_per_epoch= steps_per_epoch    # Not use for full training image set\n",
        ")\n",
        "\n",
        "print(f\"Time spent: {time.time() - start} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bePz9LHhsO0g",
        "outputId": "4537244c-6f51-447d-f954-29e55a0f1d2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time spent: 27.503771781921387 seconds\n"
          ]
        }
      ],
      "source": [
        "# Skip for now\n",
        "start = time.time()\n",
        "\n",
        "# Full evaluation on test set\n",
        "y_true, y_pred = [], []\n",
        "for images, labels in test_dataset:\n",
        "    preds = model.predict(images, verbose=0)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(tf.argmax(preds, axis=1).numpy())\n",
        "\n",
        "print(f\"Time spent: {time.time() - start} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8RjhABCc4WRl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x619NmZ2HavF"
      },
      "source": [
        "Top-1 accuracy =\n",
        "Number of correct predictions (or total # of TP) /\n",
        "Total predictions\n",
        "​\n",
        "\n",
        "\n",
        "Top-1 accuracy measures sample-level performance,\n",
        "\n",
        "avg_accuracy measures class-level performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "sLoBuwgisRL_",
        "outputId": "687e83ce-2236-4f46-f712-eb2c45748665"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class_id</th>\n",
              "      <th>class_name</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>momentum</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>epochs</th>\n",
              "      <th>Top1_accuracy</th>\n",
              "      <th>Top1_error</th>\n",
              "      <th>ELR</th>\n",
              "      <th>macro_precision</th>\n",
              "      <th>macro_recall</th>\n",
              "      <th>macro_f1</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>val_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>001.Black_footed_Albatross</td>\n",
              "      <td>0.548387</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.557377</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>30</td>\n",
              "      <td>0.579</td>\n",
              "      <td>0.421</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.596</td>\n",
              "      <td>0.581</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.043</td>\n",
              "      <td>1.774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>002.Laysan_Albatross</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>30</td>\n",
              "      <td>0.579</td>\n",
              "      <td>0.421</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.596</td>\n",
              "      <td>0.581</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.043</td>\n",
              "      <td>1.774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>003.Sooty_Albatross</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.482759</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>30</td>\n",
              "      <td>0.579</td>\n",
              "      <td>0.421</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.596</td>\n",
              "      <td>0.581</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.043</td>\n",
              "      <td>1.774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>004.Groove_billed_Ani</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>30</td>\n",
              "      <td>0.579</td>\n",
              "      <td>0.421</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.596</td>\n",
              "      <td>0.581</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.043</td>\n",
              "      <td>1.774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>005.Crested_Auklet</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.645161</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>30</td>\n",
              "      <td>0.579</td>\n",
              "      <td>0.421</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.596</td>\n",
              "      <td>0.581</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.043</td>\n",
              "      <td>1.774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>195</td>\n",
              "      <td>196.House_Wren</td>\n",
              "      <td>0.365854</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.422535</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>30</td>\n",
              "      <td>0.579</td>\n",
              "      <td>0.421</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.596</td>\n",
              "      <td>0.581</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.043</td>\n",
              "      <td>1.774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>196</td>\n",
              "      <td>197.Marsh_Wren</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.436364</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>30</td>\n",
              "      <td>0.579</td>\n",
              "      <td>0.421</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.596</td>\n",
              "      <td>0.581</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.043</td>\n",
              "      <td>1.774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>197</td>\n",
              "      <td>198.Rock_Wren</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>30</td>\n",
              "      <td>0.579</td>\n",
              "      <td>0.421</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.596</td>\n",
              "      <td>0.581</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.043</td>\n",
              "      <td>1.774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>198</td>\n",
              "      <td>199.Winter_Wren</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>30</td>\n",
              "      <td>0.579</td>\n",
              "      <td>0.421</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.596</td>\n",
              "      <td>0.581</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.043</td>\n",
              "      <td>1.774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>199</td>\n",
              "      <td>200.Common_Yellowthroat</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.763636</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>30</td>\n",
              "      <td>0.579</td>\n",
              "      <td>0.421</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.596</td>\n",
              "      <td>0.581</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.043</td>\n",
              "      <td>1.774</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     class_id                  class_name  precision    recall  f1-score  \\\n",
              "0           0  001.Black_footed_Albatross   0.548387  0.566667  0.557377   \n",
              "1           1        002.Laysan_Albatross   0.700000  0.466667  0.560000   \n",
              "2           2         003.Sooty_Albatross   0.466667  0.500000  0.482759   \n",
              "3           3       004.Groove_billed_Ani   0.583333  0.700000  0.636364   \n",
              "4           4          005.Crested_Auklet   0.588235  0.714286  0.645161   \n",
              "..        ...                         ...        ...       ...       ...   \n",
              "195       195              196.House_Wren   0.365854  0.500000  0.422535   \n",
              "196       196              197.Marsh_Wren   0.480000  0.400000  0.436364   \n",
              "197       197               198.Rock_Wren   0.461538  0.600000  0.521739   \n",
              "198       198             199.Winter_Wren   0.538462  0.700000  0.608696   \n",
              "199       199     200.Common_Yellowthroat   0.840000  0.700000  0.763636   \n",
              "\n",
              "     support  learning_rate  momentum  weight_decay  epochs  Top1_accuracy  \\\n",
              "0       30.0           0.01       0.0        0.0001      30          0.579   \n",
              "1       30.0           0.01       0.0        0.0001      30          0.579   \n",
              "2       28.0           0.01       0.0        0.0001      30          0.579   \n",
              "3       30.0           0.01       0.0        0.0001      30          0.579   \n",
              "4       14.0           0.01       0.0        0.0001      30          0.579   \n",
              "..       ...            ...       ...           ...     ...            ...   \n",
              "195     30.0           0.01       0.0        0.0001      30          0.579   \n",
              "196     30.0           0.01       0.0        0.0001      30          0.579   \n",
              "197     30.0           0.01       0.0        0.0001      30          0.579   \n",
              "198     30.0           0.01       0.0        0.0001      30          0.579   \n",
              "199     30.0           0.01       0.0        0.0001      30          0.579   \n",
              "\n",
              "     Top1_error   ELR  macro_precision  macro_recall  macro_f1  train_loss  \\\n",
              "0         0.421  0.01            0.596         0.581     0.582       0.043   \n",
              "1         0.421  0.01            0.596         0.581     0.582       0.043   \n",
              "2         0.421  0.01            0.596         0.581     0.582       0.043   \n",
              "3         0.421  0.01            0.596         0.581     0.582       0.043   \n",
              "4         0.421  0.01            0.596         0.581     0.582       0.043   \n",
              "..          ...   ...              ...           ...       ...         ...   \n",
              "195       0.421  0.01            0.596         0.581     0.582       0.043   \n",
              "196       0.421  0.01            0.596         0.581     0.582       0.043   \n",
              "197       0.421  0.01            0.596         0.581     0.582       0.043   \n",
              "198       0.421  0.01            0.596         0.581     0.582       0.043   \n",
              "199       0.421  0.01            0.596         0.581     0.582       0.043   \n",
              "\n",
              "     val_loss  \n",
              "0       1.774  \n",
              "1       1.774  \n",
              "2       1.774  \n",
              "3       1.774  \n",
              "4       1.774  \n",
              "..        ...  \n",
              "195     1.774  \n",
              "196     1.774  \n",
              "197     1.774  \n",
              "198     1.774  \n",
              "199     1.774  \n",
              "\n",
              "[200 rows x 18 columns]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Classification report\n",
        "from sklearn.metrics import classification_report\n",
        "class_map_df = pd.read_csv(base_path +\"classes.txt\", sep=\" \", header=None, names=[\"class_id\", \"class_name\"])\n",
        "class_map = dict(zip(class_map_df[\"class_id\"] - 1, class_map_df[\"class_name\"]))\n",
        "unique_labels = sorted(list(set(y_true)))\n",
        "target_names = [class_map[i] for i in unique_labels]\n",
        "report_dict = classification_report(y_true, y_pred, labels=unique_labels, target_names=target_names, output_dict=True, zero_division=0)\n",
        "\n",
        "report_df = pd.DataFrame(report_dict).transpose()\n",
        "report_df = report_df.loc[target_names].reset_index()\n",
        "report_df.rename(columns={\"index\": \"class_name\"}, inplace=True)\n",
        "class_id_map = {v: k for k, v in class_map.items()}\n",
        "report_df.insert(0, \"class_id\", report_df[\"class_name\"].map(class_id_map))\n",
        "report_df = report_df[[\"class_id\", \"class_name\", \"precision\", \"recall\", \"f1-score\", \"support\"]]\n",
        "\n",
        "# Experiment settings\n",
        "report_df[\"learning_rate\"] = learning_rate\n",
        "report_df[\"momentum\"] = momentum\n",
        "report_df[\"weight_decay\"] = weight_decay\n",
        "report_df[\"epochs\"] = num_epochs\n",
        "# report_df[\"steps_per_epoch\"] = steps_per_epoch\n",
        "report_df[\"Top1_accuracy\"] = round(model.evaluate(test_dataset, verbose=0)[1], 3)\n",
        "report_df[\"Top1_error\"] = round(1.0 - report_df[\"Top1_accuracy\"], 3)\n",
        "report_df[\"ELR\"] = round(learning_rate / (1 - momentum), 6)\n",
        "\n",
        "# Macro metrics\n",
        "macro_metrics = report_dict.get(\"macro avg\", {})\n",
        "report_df[\"macro_precision\"] = round(macro_metrics.get(\"precision\", 0.0), 3)\n",
        "report_df[\"macro_recall\"] = round(macro_metrics.get(\"recall\", 0.0), 3)\n",
        "report_df[\"macro_f1\"] = round(macro_metrics.get(\"f1-score\", 0.0), 3)\n",
        "\n",
        "# Train/val loss\n",
        "report_df[\"train_loss\"] = round(training_metrics.history[\"loss\"][-1], 3)\n",
        "report_df[\"val_loss\"] = round(training_metrics.history[\"val_loss\"][-1], 3)\n",
        "\n",
        "# Final report\n",
        "report_df\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf113-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
