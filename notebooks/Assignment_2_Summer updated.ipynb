{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f32a86cfae6018c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:32:10.838555Z",
     "start_time": "2025-05-20T00:32:06.916174Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dff607-2f32-4904-b061-5b552fb2d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history):\n",
    "    \"\"\"\n",
    "    绘制训练过程中的 loss 和 sparse_categorical_accuracy 曲线。\n",
    "    参数：\n",
    "        history : tf.keras.callbacks.History 对象\n",
    "    \"\"\"\n",
    "    historydf = pd.DataFrame(history.history, index=history.epoch)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    historydf[[\"loss\", \"val_loss\", \"sparse_categorical_accuracy\", \"val_sparse_categorical_accuracy\"]].plot(\n",
    "        ylim=(0, max(1.0, historydf.values.max())),\n",
    "        title=\"Training and Validation Loss / Accuracy\",\n",
    "        grid=True,\n",
    "        figsize=(10, 6)\n",
    "    )\n",
    "\n",
    "    final_loss = history.history['loss'][-1]\n",
    "    final_acc = history.history['sparse_categorical_accuracy'][-1]\n",
    "    plt.title(f'Final Loss: {final_loss:.3f}, Final Accuracy: {final_acc:.3f}')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Metric Value\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_multiple_histories_with_annotations(histories, labels=None, metric=\"sparse_categorical_accuracy\",\n",
    "                                             figsize=(14, 6), save_path=None, dpi=300, file_format=\"png\"):\n",
    "    \"\"\"\n",
    "    绘制多个 history 对象的训练/验证曲线（支持不同颜色/线型，标注最高点，导出图像）\n",
    "\n",
    "    参数：\n",
    "    - histories: list of tf.keras.callbacks.History objects\n",
    "    - labels: list of str, 用于标注每个模型\n",
    "    - metric: str, 训练指标名，如 \"sparse_categorical_accuracy\", \"loss\"\n",
    "    - figsize: tuple, 图像尺寸\n",
    "    - save_path: str, 文件保存路径（无扩展名）\n",
    "    - dpi: int, 导出图像分辨率\n",
    "    - file_format: str, 'png' 或 'svg'\n",
    "    \"\"\"\n",
    "\n",
    "    if labels is None:\n",
    "        labels = [f\"Model {i+1}\" for i in range(len(histories))]\n",
    "\n",
    "    colors = plt.cm.get_cmap('tab10', len(histories))  # 不同模型不同颜色\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # === 子图1：训练曲线（实线）\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i, (hist, label) in enumerate(zip(histories, labels)):\n",
    "        plt.plot(hist.epoch, hist.history[metric], linestyle='-', color=colors(i), label=f\"{label} (train)\")\n",
    "    plt.title(f\"Training {metric}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # === 子图2：验证曲线（虚线 + 标注）\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for i, (hist, label) in enumerate(zip(histories, labels)):\n",
    "        val_metric = f\"val_{metric}\"\n",
    "        val_values = hist.history[val_metric]\n",
    "        epochs = hist.epoch\n",
    "        plt.plot(epochs, val_values, linestyle='--', color=colors(i), label=f\"{label} (val)\")\n",
    "\n",
    "        # 自动标注最大 val accuracy 位置\n",
    "        best_epoch = int(pd.Series(val_values).idxmax())\n",
    "        best_value = val_values[best_epoch]\n",
    "        plt.scatter(best_epoch, best_value, color=colors(i), marker='o')\n",
    "        plt.text(best_epoch, best_value + 0.01, f\"{best_value:.3f}\", fontsize=9, ha='center', color=colors(i))\n",
    "\n",
    "    plt.title(f\"Validation {metric}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 导出图像\n",
    "    if save_path:\n",
    "        full_path = f\"{save_path}.{file_format}\"\n",
    "        plt.savefig(full_path, dpi=dpi, format=file_format)\n",
    "        print(f\"✅ 图像已保存为 {full_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf62a5cc3f776da",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60eaf0e-4f0e-48a6-babf-cea234893c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet normalization stats\n",
    "IMAGENET_MEAN = tf.constant([0.485, 0.456, 0.406], dtype=tf.float32)\n",
    "IMAGENET_STD = tf.constant([0.229, 0.224, 0.225], dtype=tf.float32)\n",
    "\n",
    "# Custom preprocessing function\n",
    "def preprocess_train(image, label):\n",
    "    image = tf.image.resize_with_pad(image, 256, 256)  # 短边缩放到256，pad长边\n",
    "    image = tf.image.random_crop(image, size=(224, 224, 3))  # 随机裁剪\n",
    "    image = tf.image.random_flip_left_right(image)  # 随机水平翻转\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)  # 明亮度抖动\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # 归一化到0~1\n",
    "    image = (image - IMAGENET_MEAN) / IMAGENET_STD  # 使用ImageNet均值标准化\n",
    "    return image, label\n",
    "\n",
    "def preprocess_val(image, label):\n",
    "    image = tf.image.resize_with_pad(image, 256, 256)\n",
    "    image = tf.image.central_crop(image, central_fraction=0.875)  # 近似224 crop\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = (image - IMAGENET_MEAN) / IMAGENET_STD\n",
    "    return image, label\n",
    "\n",
    "# Load raw dataset\n",
    "raw_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"../data/CUB_200_2011/CUB_200_2011/images\",\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=(256, 256),  # 初步resize到统一尺寸（不作变形）\n",
    "    batch_size=None,  # 返回未批量化的 (image, label), 保证 map 时传入的是单张图像\n",
    "    shuffle=True,\n",
    "    seed=888\n",
    ")\n",
    "\n",
    "# Train/Val split\n",
    "total_size = 11788  # CUB-200-2011 总样本数\n",
    "train_size = 5994   # 按照官方 split\n",
    "val_size = total_size - train_size\n",
    "\n",
    "train_ds = raw_dataset.take(train_size).map(preprocess_train).batch(256).shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = raw_dataset.skip(train_size).map(preprocess_val).batch(256).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9978d60228b3a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:34:06.935141Z",
     "start_time": "2025-05-20T00:34:06.692025Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the dataset\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(images.shape)  # (256, 224, 224, 3)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35452960bfe97464",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b50dd41-58cd-49dd-a1a2-f553771b21e7",
   "metadata": {},
   "source": [
    "## Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d3865f902d8c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:34:31.619143Z",
     "start_time": "2025-05-20T00:34:29.383970Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet101V2\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "def build_model():\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    base_model = ResNet101V2(weights=\"imagenet\", include_top=False, input_tensor=inputs)\n",
    "    base_model.trainable = True  # Full fine-tuning\n",
    "\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    # x = layers.Dropout(0.2)(x)  # optional\n",
    "\n",
    "    outputs = layers.Dense(200, activation=\"softmax\", name=\"Predictions\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.summary(show_trainable=True)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d5911e-1987-456b-956d-ccc398987796",
   "metadata": {},
   "source": [
    "## Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb02032b6d9a0334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:34:40.079873Z",
     "start_time": "2025-05-20T00:34:40.077182Z"
    }
   },
   "outputs": [],
   "source": [
    "def compile_model(model, lr=0.01, m=0.9, wd=0.0001):\n",
    "    optimizer = tf.keras.optimizers.SGD(\n",
    "        learning_rate=lr,\n",
    "        momentum=m,\n",
    "        weight_decay=wd  # TF ≥ 2.9 iff available, our tf.__version__ = 2.16\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce267ef04a30ccd8",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d3e08c-2956-45d2-be9b-0d9a72437d8a",
   "metadata": {},
   "source": [
    "### step decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbce7c5-8281-450c-b3e3-4e11a395b186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step Decay LearningRateScheduler Function（Li et al., 2020）\n",
    "def step_decay(epoch):\n",
    "    if epoch < 150:\n",
    "        return 0.01\n",
    "    elif epoch < 250:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17076bb-3eb8-411c-ad74-96c4ce6fa650",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa4580a-2296-4024-b751-21b4167ace79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "\n",
    "checkpoint_path = \"checkpoints/best_model.keras\"\n",
    "log_dir = \"logs/single_run\"\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "        mode=\"min\",\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1,\n",
    "        write_graph=True,\n",
    "        write_images=True\n",
    "    ),\n",
    "    lr_callback\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92957e-430e-4681-acc3-e0447929a568",
   "metadata": {},
   "source": [
    "# Output Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa28934-fb4b-4cb8-ad11-ba9d1547eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# output dir\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "base_ckpt_dir = f\"checkpoints_grid_{timestamp}\"\n",
    "base_log_dir = f\"logs_grid_{timestamp}\"\n",
    "os.makedirs(base_ckpt_dir, exist_ok=True)\n",
    "os.makedirs(base_log_dir, exist_ok=True)\n",
    "\n",
    "# result initial\n",
    "results = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b9131f-56c3-4ead-a093-513bd77b8564",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd0e428-fb4c-4de6-9957-b7982e273389",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T00:35:04.141805Z",
     "start_time": "2025-05-20T00:35:04.139227Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment(lr=0.01, m=0.9, wd=0.0001, tag=None, epochs=1, use_early_stopping=True):\n",
    "    \"\"\"\n",
    "    构建、编译并训练模型，支持指定超参数和输出路径。\n",
    "    \"\"\"\n",
    "    model = build_model()\n",
    "    model = compile_model(model, lr=lr, m=m, wd=wd)\n",
    "\n",
    "    if tag is None:\n",
    "        tag = f\"lr_{lr}_m_{m}\"\n",
    "\n",
    "    ckpt_dir = os.path.join(base_ckpt_dir, tag)\n",
    "    log_dir = os.path.join(base_log_dir, tag)\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(ckpt_dir, \"model_best.keras\"),\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "            mode=\"min\",\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir=log_dir,\n",
    "            histogram_freq=1,\n",
    "            write_graph=True,\n",
    "            write_images=True\n",
    "        ),\n",
    "        lr_callback\n",
    "    ]\n",
    "\n",
    "    if use_early_stopping:\n",
    "        callbacks.append(\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=15,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    best_val_loss = min(history.history[\"val_loss\"])\n",
    "    best_val_acc = max(history.history[\"val_sparse_categorical_accuracy\"])\n",
    "    best_epoch = history.history[\"val_loss\"].index(best_val_loss)\n",
    "\n",
    "    return {\n",
    "        \"learning_rate\": lr,\n",
    "        \"momentum\": m,\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"best_val_accuracy\": best_val_acc,\n",
    "        \"epoch\": best_epoch,\n",
    "        \"history\": history\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5494f2c0-0ba0-439f-8f2e-5b9d2b712590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search Parameter\n",
    "learning_rates = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "momentums = [0.0, 0.8, 0.9, 0.95, 0.99]\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for m in momentums:\n",
    "        print(f\\\"\\\\n🚀 Training: lr={lr}, m={m}\\\")\n",
    "        res = run_experiment(lr=lr, m=m, epochs=300, use_early_stopping=False)\n",
    "        results.append({k: res[k] for k in res if k != \\\"history\\\"})  # history 可选保存\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c7cfe-0275-455b-bc48-d8a69feee57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f\"grid_search_results_{timestamp}.csv\", index=False)\n",
    "\n",
    "# 曲线图 1：不同学习率下 val accuracy 曲线（按 momentum 分组）\n",
    "plt.figure(figsize=(10, 6))\n",
    "for m in sorted(results_df['momentum'].unique()):\n",
    "    subset = results_df[results_df['momentum'] == m]\n",
    "    plt.plot(subset['learning_rate'], subset['best_val_accuracy'], marker='o', label=f'm={m}')\n",
    "\n",
    "plt.title(\"Validation Accuracy vs Learning Rate\")\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Best Validation Accuracy\")\n",
    "plt.xscale('log')  # 对学习率使用 log 坐标更直观\n",
    "plt.legend(title=\"Momentum\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "acc_curve_path = f\"val_accuracy_curve_{timestamp}.png\"\n",
    "plt.savefig(acc_curve_path, dpi=300)\n",
    "plt.show()\n",
    "print(f\"✅ 曲线图（Accuracy）已保存为：{acc_curve_path}\")\n",
    "\n",
    "\n",
    "# 曲线图 2：不同动量下 val accuracy 曲线（按 learning_rate 分组）\n",
    "plt.figure(figsize=(10, 6))\n",
    "for lr in sorted(results_df['learning_rate'].unique()):\n",
    "    subset = results_df[results_df['learning_rate'] == lr]\n",
    "    plt.plot(subset['momentum'], subset['best_val_accuracy'], marker='o', label=f'lr={lr}')\n",
    "\n",
    "plt.title(\"Validation Accuracy vs Momentum\")\n",
    "plt.xlabel(\"Momentum\")\n",
    "plt.ylabel(\"Best Validation Accuracy\")\n",
    "plt.legend(title=\"Learning Rate\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "momentum_curve_path = f\"val_accuracy_vs_momentum_curve_{timestamp}.png\"\n",
    "plt.savefig(momentum_curve_path, dpi=300)\n",
    "plt.show()\n",
    "print(f\"✅ 曲线图（vs Momentum）已保存为：{momentum_curve_path}\")\n",
    "\n",
    "# 热力图\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 保存 CSV 文件\n",
    "results_df = pd.DataFrame(results)\n",
    "csv_path = f\"grid_search_results_{timestamp}.csv\"\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f\"\\n✅ 所有实验完成，结果已保存：{csv_path}\")\n",
    "\n",
    "# === 输出 Heatmap 图像 ===\n",
    "\n",
    "# Pivot 成矩阵形式\n",
    "acc_matrix = results_df.pivot(index=\"momentum\", columns=\"learning_rate\", values=\"best_val_accuracy\")\n",
    "loss_matrix = results_df.pivot(index=\"momentum\", columns=\"learning_rate\", values=\"best_val_loss\")\n",
    "\n",
    "# 绘制 Accuracy 热力图\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(acc_matrix, annot=True, fmt=\".3f\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Validation Accuracy Heatmap\")\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Momentum\")\n",
    "plt.tight_layout()\n",
    "acc_fig_path = f\"val_accuracy_heatmap_{timestamp}.png\"\n",
    "plt.savefig(acc_fig_path, dpi=300)\n",
    "plt.show()\n",
    "print(f\"✅ 准确率图像已保存为：{acc_fig_path}\")\n",
    "\n",
    "# （可选）绘制 Loss 热力图\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(loss_matrix, annot=True, fmt=\".3f\", cmap=\"Reds_r\")\n",
    "plt.title(\"Validation Loss Heatmap\")\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Momentum\")\n",
    "plt.tight_layout()\n",
    "loss_fig_path = f\"val_loss_heatmap_{timestamp}.png\"\n",
    "plt.savefig(loss_fig_path, dpi=300)\n",
    "plt.show()\n",
    "print(f\"✅ 损失图像已保存为：{loss_fig_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a33c412-cc4c-4cda-a224-a882c5ead7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow M1)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
